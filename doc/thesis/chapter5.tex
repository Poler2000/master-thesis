\chapter{Ulepszenie algorytmu NodeSketch z wykorzystaniem FastExpSketch}
\section{Motywacja}
    Algorytm NodeSketch cechuje się wysoką efektywnością pamięciową i czasową. Ekeprymenty pokazują, że osiąga on także dobre rezultaty na rzeczywistych danych\cite{Yang_Rosso_Li_Cudre-Mauroux_2019}. 
    Niemniej jednak, gama operacji, które można wykonać na wynikowych szkicach jest dość ograniczona. Ponadto, NodeSketch w swej bazowej postaci nie uwzględnia wag krawędzi w zanurzeniach, co potencjalnie ogranicza jego użyteczność dla grafów ważonych.   
    W niniejszym rozdziale przyglądamy się generalizacji algorytmu NodeSketch, polegającej na wykorzystaniu metody FastExpSketch do szkicowania wierzchołków. Wyjaśniamy zasadę działania tej metody, przedstawiamy jej implementację i analizujemy jej złożoność. Zwracamy także uwagę na korzyści płynące z zastosowania takiego podejścia, takie jak możliwość wykonywania operacji teoriomnogościowych na szkicach, czy uwzględnienie wag krawędzi.

\section{Idea}
    NodeSketch wykorzystuje inverse sampling theorem do generowania próbek z rozkładu wykładniczego. Konkretnie $j$-ta pozycja w zanurzeniu jest obliczana jako: 
    \[  
        S_j = \argmin_{i \in \{1,2,\dots, D\}} \frac{-\log h_{j}(i)}{V_i},
    \] 
    gdzie $V = (V_1, V_2, \dots, V_D)$ to wektor sąsiedztwa. Łatwo zauważyć, że jest to bardzo podobny pomysł do tego, na którym opierają się algorytmy ExpSketch i FastExpSketch. Podstawowa różnica polega na tym, że w przypadku NodeSketch, w szkicu przechowywane będą indeksy wierzchołków, podczas gdy w przypadku ExpSketch - rzeczywista wartość wygenerowana z rozkładu wykładniczego. Pozwala to między innymi na lepsze uwzględnienie wag krawędzi w zanurzeniach. Dlatego też, naturalnym krokiem wydaje się zastąpienie tej części algorytmu NodeSketch szkicowaniem wierzchołków z wykorzystaniem FastExpSketch.

    Przedstawiona modyfikacja powinna zmiejszyć również średnią liczbę wykonywanych operacji, ze względu na bardziej efektywne podejście do szkicowania. To założenie zostało zweryfikowane eksperymentalnie w kolejnym rozdziale \ref{sec:performance}. Pseudokod zmodyfikowanej wersji algorytmu, którą określać będziemy dalej jako EdgeSketch, przedstawia pseudokod \ref{alg:edge_sketch}. W każdej iteracji głównej pętli rozważamy jeden wiersz w macierzy sąsiedztwa, a więc jeden  wierzchołek. W linijce $2$ wybieramy sąsiadów wierzchołka oraz wagi połączeń. Etykieta krawędzi powstaje przez połączenie etykiet wierzchołków w porządku leksykograficznym. Wynika to z faktu, że rozważamy grafy nieskierowane i krawędź $(a,b)$ powinna być nierozróżnialna od krawędzi $(b,a)$. Następnie, krawędzie te są przekazywane do metody FastExpSketch, która generuje na ich podstawie właściwe szkice.  

    \begin{algorithm}
        \caption{EdgeSketch($\tilde{A},m$)}\label{alg:edge_sketch}
        \ForEach{\textnormal{rząd} $r$ \textnormal{w} $\tilde{A}$}{
            $ns \gets \{((\min(i,r) || \max(i,r)),\tilde{A}[r,i]) : \tilde{A}[r,i] \neq 0\}$\;
            $S^{r} \gets FastExpSketch(ns, m)$\;
        }
        \Return{$S(k)$}
    \end{algorithm}

    Co ciekawe, w tak zmodyfikowanym algorytmie można pominąć parametr $k$ przy tworzeniu zanurzeń. Zamiast tego, sąsiedztwo wyższych rzędów może zostać wykorzystane poprzez odpowiednie operacje na szkicu. Jako przykład, a zarazem ciekawe zastosowanie algorytmu, będziemy rozważać zadanie rekonstrukcji grafu. Konkretnie, zależeć nam będzie na wyznaczeniu na podstawie szkicu $t$ najbardziej prawdopodobnych krawędzi. W tym celu wykorzystane zostanie podobieństwo Jaccarda między zanurzaniami wierzchołków. Procedura polega na obliczeniu macierzy podobieństwa $simM$ między każdymi dwoma wierzchołkami w grafie, co ilustruje pseudokod \ref{alg:compute_sim_matrix}. W przypadku oryginalnego algorytmu NodeSketch, operacja ta jest wykonywana na podstawie zanurzeń $k$-tego rzędu. Z kolei w przypadku EdgeSketcha, macierze podobieństwa są obliczane oddzielnie dla różnych stopni sąsiedztwa. Dla $k = 3$, do reprezentacji wierzchołka używana jest suma mnogościowa zanurzeń tego wierzchołka i jego sąsiadów, dla $k = 4$ wszystkich wierzchołków odległych o co najwyżej $2$ i tak dalej. Ostateczny rezultat powstaje przez połączenie wszystkich macierzy podobieństwa. Parametr rozkładu wykładniczego $\alpha$ decyduje o tym, jakie wagi nadawane są macierzom wyższych rzędów, według wzoru:
    \begin{equation}  \label{eq:sim_matrix}  
        simM = \sum\limits_{k = 2}^{K} \alpha^{k-2} simM_{k}.
    \end{equation}
    
    \begin{algorithm}
        \caption{ComputeSimilarityMatrix($embeddings, n, m$)}\label{alg:compute_sim_matrix}
        $simM \gets [n,n]$ \tcp*{pusta macierz $n \times n$}
        \ForEach{$i \in \{1,\dots,n\}$}{
            \ForEach{$j \in \{i,\dots,n\}$}{
                $simCount \gets 0$\; 
                \ForEach{$l \in \{1,\dots,m\}$}{
                    \uIf{$embeddings[i,l] = embeddings[j,l]$}{
                        $simCount \gets simCount + 1$\;
                    }
                }

                $simM[i,j] = simM[j,i] \gets simCount / m$
            }
        }
        \Return{$simM$}
    \end{algorithm}
    \subsection{Złożoność obliczeniowa}
    Dla uproszczenia, będziemy rozważać złożoność algorytmów dla grafów nieważonych. Podstawowy algorytm NodeSketch przetwarza po kolei $|V|$ wierzchołków, dla każdego z nich generując $m|V|$ próbek, co daje łączną złożoność $O(m(|V|)^2)$. EdgeSketch również przetwarza po kolei wierzchołki. Dla każdego z nich wyszukiwani są sąsiedzi w czasie liniowym. Z kolei czas poterzebny na stworzenie zanurzeń dla danego wierzchołka zależy od liczby krawędzi z niego wychodzących. Liczba ta nie przekroczy jednak oczywiście liczby wierzchłków, dlatego możemy przyjąć górne ograniczenie w postaci złożoności $O(m H_m H_{|V|}) = O(m \ln(m) \ln(|V|))$. Daje to łączną złożoność algorytmu $O((|V|)^2 + |V|(m \ln(m) \ln(|V|)))$ lub, traktując $m$ jako stałą, $O((|V|)^2 + |V|(\ln(|V|)))$. Choć oczywiście pierwszy składnik sumy jest asymptotycznie dominujący, w praktyce dla wielu grafów drugi składnik może okazać się kluczowy, głównie ze względu na stosunkowo wysoki koszt obliczania haszy. Warto też zauważyć, że obliczenia wykonywane w każdej iteracji pętli są niezależne od siebie, co pozwala na łatwe zrównoleglenie obliczeń. 
\chapter{Ulepszenie algorytmu NodeSketch z wykorzystaniem FastExpSketch}
\section{Motywacja}
    Algorytm NodeSketch cechuje się wysoką efektywnością pamięciową i czasową. Eksperymenty pokazują, że osiąga on także dobre rezultaty na rzeczywistych danych \cite{Yang_Rosso_Li_Cudre-Mauroux_2019}. 
    Niemniej jednak, gama operacji, które można wykonać na wynikowych szkicach jest dość ograniczona. Ponadto, NodeSketch w swej bazowej postaci nie uwzględnia wag krawędzi w zanurzeniach, co potencjalnie ogranicza jego użyteczność dla grafów ważonych.   
    W niniejszym rozdziale przyglądamy się generalizacji algorytmu NodeSketch, polegającej na wykorzystaniu metody FastExpSketch do szkicowania wierzchołków. Wyjaśniamy zasadę działania tej metody, przedstawiamy jej implementację i analizujemy jej złożoność. Zwracamy także uwagę na korzyści płynące z zastosowania takiego podejścia, takie jak możliwość wykonywania operacji teoriomnogościowych na szkicach, czy uwzględnienie wag krawędzi.

\section{Idea}
    NodeSketch wykorzystuje \textit{inverse sampling theorem} do generowania próbek z rozkładu wykładniczego. Konkretnie $j$-ta pozycja w zanurzeniu jest obliczana jako: 
    \[  
        S_j = \argmin_{i \in \{1,2,\dots, D\}} \frac{-\log h_{j}(i)}{V_i},
    \] 
    gdzie $V = (V_1, V_2, \dots, V_D)$ to wektor sąsiedztwa. Łatwo zauważyć, że jest to bardzo podobny pomysł do tego, na którym opierają się algorytmy ExpSketch i FastExpSketch. Podstawowa różnica polega na tym, że w przypadku NodeSketch, w szkicu przechowywane będą indeksy wierzchołków, podczas gdy w przypadku ExpSketch - rzeczywista wartość wygenerowana z rozkładu wykładniczego. Pozwala to między innymi na lepsze uwzględnienie wag krawędzi w zanurzeniach. Dlatego też, naturalnym krokiem wydaje się zastąpienie tej części algorytmu NodeSketch szkicowaniem wierzchołków z wykorzystaniem FastExpSketch.

    Przedstawiona modyfikacja powinna zmniejszyć również średnią liczbę wykonywanych operacji, ze względu na bardziej efektywne podejście do szkicowania. To założenie zostało zweryfikowane eksperymentalnie w Rozdziale \ref{sec:performance}. Działanie zmodyfikowanej wersji algorytmu, którą określać będziemy dalej jako EdgeSketch, przedstawia \red{Algorytm} \ref{alg:edge_sketch}. W każdej iteracji głównej pętli rozważamy jeden wiersz w macierzy sąsiedztwa, a więc jeden  wierzchołek. W wewnętrznej pętli wybieramy jego sąsiadów oraz wagi połączeń. Etykieta krawędzi powstaje przez połączenie etykiet wierzchołków w porządku leksykograficznym. Wynika to z faktu, że rozważamy grafy nieskierowane i krawędź $(a,b)$ powinna być nierozróżnialna od krawędzi $(b,a)$. Następnie, krawędzie te są przekazywane do metody FastExpSketch, która generuje na ich podstawie właściwe szkice.  

    \begin{algorithm}
        \caption{EdgeSketch($\tilde{A},m$)}\label{alg:edge_sketch}
        \ForEach{\textnormal{rząd} $r$ \textnormal{w} $\tilde{A}$}{
            $ns \gets [\,]$ \tcp*{lista sąsiadów}
            \ForEach{$i \in \{1,\dots,|V|\}$}{
                \If{$\tilde{A}[r,i] \neq 0$}{
                    $ns \gets ns \cup \{((\min(i,r) || \max(i,r)),\tilde{A}[r,i])\}$\;
                }
            }
            $S^{r} \gets FastExpSketch(ns, m)$\;
        }
        \Return{$S$}
    \end{algorithm}

    Co ciekawe, w tak zmodyfikowanym algorytmie można pominąć parametr $k$ przy tworzeniu zanurzeń. Zamiast tego, sąsiedztwo wyższych rzędów może zostać uzyskane poprzez odpowiednie operacje na szkicu. Jako przykład, a zarazem ciekawe zastosowanie algorytmu, będziemy rozważać zadanie rekonstrukcji grafu. Konkretnie, zależeć nam będzie na wyznaczeniu na podstawie szkicu $t$ najbardziej prawdopodobnych krawędzi. W tym celu wykorzystane zostanie podobieństwo Jaccarda między zanurzaniami wierzchołków. Procedura polega na obliczeniu macierzy podobieństwa $simM$ między każdymi dwoma wierzchołkami w grafie, co ilustruje Algorytm \ref{alg:compute_sim_matrix}. W przypadku oryginalnego algorytmu NodeSketch, operacja ta jest wykonywana na podstawie zanurzeń $k$-tego rzędu. Z kolei w przypadku EdgeSketcha, macierze podobieństwa mogą być obliczane oddzielnie dla różnych stopni sąsiedztwa. Na przykład, dla $k = 3$, do reprezentacji wierzchołka używana jest suma teoriomnogościowa zanurzeń tego wierzchołka i jego sąsiadów, dla $k = 4$ wszystkich wierzchołków odległych o co najwyżej $2$ i tak dalej. Ostateczny rezultat powstaje przez połączenie wszystkich macierzy podobieństwa. Parametr rozkładu wykładniczego $\alpha$ decyduje o tym, jakie wagi nadawane są macierzom wyższych rzędów, według wzoru:
    \begin{equation}  \label{eq:sim_matrix}  
        simM = \sum\limits_{k = 2}^{K} \alpha^{k-2} simM_{k}.
    \end{equation}
    \textcolor{red}{Powyższa formuła, jak również ogólna idea za nią stojąca, pochodzi z nieopublikowanej jeszcze pracy dr inż. Jakuba Lemiesza oraz prof. Philippe'a Cudré-Mauroux. Spośród obliczonych wartości prawdopodobieństw, wybierane jest $t$ największych. Wyznaczają one krawędzie w zrekonstruowanym grafie.} 
    
    \begin{algorithm}
        \caption{ComputeSimilarityMatrix($embeddings, n, m$)}\label{alg:compute_sim_matrix}
        $simM \gets [n,n]$ \tcp*{pusta macierz $n \times n$}
        \ForEach{$i \in \{1,\dots,n\}$}{
            \ForEach{$j \in \{i,\dots,n\}$}{
                $simCount \gets 0$\; 
                \ForEach{$l \in \{1,\dots,m\}$}{
                    \uIf{$embeddings[i,l] = embeddings[j,l]$}{
                        $simCount \gets simCount + 1$\;
                    }
                }

                $simM[i,j] = simM[j,i] \gets simCount / m$
            }
        }
        \Return{$simM$}
    \end{algorithm}
    \subsection{Złożoność obliczeniowa}
    \label{sec:complexity}
    Dla uproszczenia, będziemy rozważać złożoność algorytmów dla grafów nieważonych. Rozważmy działanie algorytmu NodeSketch dla $k = 2$. \textcolor{red}{Przetwarza on po kolei $|V|$ wierzchołków, dla każdego z nich generując szkic o $m$ elementach.Każdy z tych elementów powstaje poprzez generowanie próbek z rozkładu wykładniczego, po jednej dla każdego z pozostałych wierzchołków w grafie. Daje to złożoność $O(m|V|)$ dla jednej iteracji i łącznie $O(m(|V|)^2)$ dla całej procedury. Algorytm wykonuje stałą liczbę $k - 2$ wywołań rekurencyjnych. W przypadku wyższych $k$, oprócz generowania próbek, konstruowany jest także wektor sąsiedztwa wyższego rzędu. W oryginalnej wersji algorytmu\ref{alg:node_sketch} krok ten wymaga $O(m|V|^2)$ operacji dla każdego wierzchołka, ponieważ zakłada przejście po każdej pozycji w $m$-elementowym szkicu $|V|^2$ razy. Łatwo jednak zauważyć, że zamiast obliczać 
    \[
        \sum\limits_{j = 1}^{m} \mathbbm{1}_{[S_{j}^{n}(k - 1) = i]}
    \]
    oddzielnie dla każdego $i \in \{1,2,\dots,|V|\}$, można podliczać wystąpienia różnych $i$ i zapamiętać wyniki w strukturze takiej jak słownik. Pozwala to na zredukowanie złożoności tworzenia wektora sąsiedztwa do $O(m|V|)$. Stąd cały algorytm ma złożoność $O(m(|V|)^2)$.}
    
     EdgeSketch również przetwarza po kolei wierzchołki. Dla każdego z nich wyszukiwani są sąsiedzi w czasie liniowym. Z kolei czas potrzebny na stworzenie zanurzeń dla danego wierzchołka zależy od liczby krawędzi z niego wychodzących. Liczba ta nie przekroczy jednak oczywiście liczby wierzchołków. \textcolor{red}{Dlatego możemy przyjąć, że liczba elementów przekazywanych do procedury \texttt{FastExpSketch} jest rzędu $O(|V|)$. Pesymistyczna liczba operacji wykonywanych przez tą procedurę jest rzędu $O(m|V|)$, stąd łączną złożoność całego algorytmu ExpSketch można wyrazić jako $O(m(|V|)^2)$, tak samo jak w algorytmie \texttt{NodeSketch}.} 
     
     \textcolor{red}{Niemniej jednak, warto rozważyć także złożoność w średnim przypadku. Możemy przyjąć średnią złożoność \texttt{FastExpSketch} dla elementów o równej wadze. Przypomnijmy, że wynosi ona w takim przypadku $O(m H_m H_{|V|}) = O(m \ln(m) \ln(|V|))$. Daje to łączną złożoność algorytmu $O((|V|)^2 + |V|(m \ln(m) \ln(|V|)))$ lub, traktując $m$ jako stałą, $O((|V|)^2 + |V|(\ln(|V|)))$. Pierwszy składnik sumy odpowiada wyszukiwaniu sąsiadów każdego wierzchołka. Z kolei drugi związany jest z wywołaniami procedury  \texttt{FastExpSketch}}. Choć oczywiście pierwszy składnik sumy jest asymptotycznie dominujący, w praktyce dla wielu grafów drugi składnik może okazać się kluczowy, głównie ze względu na stosunkowo wysoki koszt obliczania funkcji haszującej. Warto też zauważyć, że obliczenia wykonywane w każdej iteracji pętli są niezależne od siebie, co pozwala na łatwe zrównoleglenie obliczeń. 
     
     \textcolor{red}{Wynikiem działania obu algorytmów są szkice o rozmiarze $m \times |V|$. NodeSketch konstruuje także wektory sąsiedztwa wyższych rzędów, z których każdy ma $O(|V|)$ elementów, ale ponieważ są one generowane oddzielnie, po jednym w każdej iteracji, nie zwiększa to asymptotycznej złożoności obliczeniowej. Z kolei EdgeSketch alokuje dodatkową pamięć na przechowywanie listy sąsiadów w każdej iteracji pętli, ale jest ona także rzędu $O(|V|)$, więc ogólna złożoność pamięciowa obu algorytmów wynosi $O(m|V|)$.}
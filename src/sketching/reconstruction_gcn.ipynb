{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import cdist\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [1. 0.]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "mat = loadmat('..\\\\results\\\\var_k\\dblp\\\\res_dblp_exp_2_002_128.mat')\n",
    "features_matrix = mat['embs']\n",
    "\n",
    "mat = loadmat(\"../data/dblp.mat\")\n",
    "A = mat[\"network\"]\n",
    "labels_matrix = mat[\"group\"]\n",
    "labels_count = labels_matrix.shape[1]\n",
    "\n",
    "groups = labels_matrix.toarray()\n",
    "A = A.toarray()\n",
    "X = features_matrix\n",
    "\n",
    "print(groups[:5, :5])\n",
    "print(A[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, A_train, A_test = train_test_split(X, A, test_size=0.25, random_state=2137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(num_nodes, train_percent=0.8, val_percent=0.1):\n",
    "    \"\"\"\n",
    "    Randomly assign train, validation, and test masks for the nodes in the graph.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_nodes (int): Total number of nodes in the graph.\n",
    "    - train_percent (float): Percentage of nodes to include in the training set.\n",
    "    - val_percent (float): Percentage of nodes to include in the validation set.\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple of Tensors: (train_mask, val_mask, test_mask)\n",
    "    \"\"\"\n",
    "    indices = np.random.permutation(num_nodes)\n",
    "    train_size = int(num_nodes * train_percent)\n",
    "    val_size = int(num_nodes * val_percent)\n",
    "\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[indices[:train_size]] = True\n",
    "    val_mask[indices[train_size:train_size + val_size]] = True\n",
    "    test_mask[indices[train_size + val_size:]] = True\n",
    "\n",
    "    return train_mask, val_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_torch_geo_data(features, adjacency_matrix, num_nodes):\n",
    "    edge_index = adjacency_to_edge_index(adjacency_matrix)\n",
    "    x = features_to_tensor(features)\n",
    "    train_mask, val_mask, test_mask = create_masks(num_nodes)\n",
    "    data = Data(x=x, edge_index=edge_index, train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def adjacency_to_edge_index(adjacency_matrix):\n",
    "    # Find the indices of nonzero elements (edges) in the adjacency matrix\n",
    "    src, dst = adjacency_matrix.nonzero()\n",
    "    # Create a tensor containing edge pairs\n",
    "    edge_index = np.vstack([src, dst])\n",
    "    return torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "def features_to_tensor(features):\n",
    "    return torch.tensor(features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x  # Output is node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edge_scores(node_embeddings):\n",
    "    # Using dot product to score edges\n",
    "    scores = torch.matmul(node_embeddings, node_embeddings.t())\n",
    "    return torch.sigmoid(scores)  # Use sigmoid to map scores to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "Data(x=[13326, 128], edge_index=[2, 68562], train_mask=[13326], val_mask=[13326], test_mask=[13326])\n"
     ]
    }
   ],
   "source": [
    "num_features = X.shape[1]\n",
    "print(num_features)\n",
    "num_classes = 13326  # You'll need to set this based on your dataset\n",
    "data = create_torch_geo_data(X, A, num_classes)\n",
    "\n",
    "# Initialize model\n",
    "model = GCN(num_features, num_classes)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_set(edge_index):\n",
    "    edge_set = set()\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        edge_set.add((edge_index[0, i].item(), edge_index[1, i].item()))\n",
    "        edge_set.add((edge_index[1, i].item(), edge_index[0, i].item()))  # Add reverse direction for undirected graphs\n",
    "    return edge_set\n",
    "\n",
    "edge_set = create_edge_set(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_samples(edge_set, num_nodes, num_neg_samples):\n",
    "    neg_edge_index = []\n",
    "    while len(neg_edge_index) < num_neg_samples:\n",
    "        i = np.random.randint(0, num_nodes)\n",
    "        j = np.random.randint(0, num_nodes)\n",
    "        if i != j and (i, j) not in edge_set:\n",
    "            neg_edge_index.append([i, j])\n",
    "    return torch.tensor(neg_edge_index).t()\n",
    "\n",
    "negative_edge_index = get_negative_samples(edge_set, data.num_nodes, num_neg_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 starting\n",
      "epoch: 0 computing scores\n",
      "epoch: 0 concluding\n",
      "epoch: 1 starting\n",
      "epoch: 1 computing scores\n",
      "epoch: 1 concluding\n",
      "epoch: 2 starting\n",
      "epoch: 2 computing scores\n",
      "epoch: 2 concluding\n",
      "epoch: 3 starting\n",
      "epoch: 3 computing scores\n",
      "epoch: 3 concluding\n",
      "epoch: 4 starting\n",
      "epoch: 4 computing scores\n",
      "epoch: 4 concluding\n",
      "epoch: 5 starting\n",
      "epoch: 5 computing scores\n",
      "epoch: 5 concluding\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(6):\n",
    "    print(f\"epoch: {epoch} starting\")\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(data)\n",
    "\n",
    "    print(f\"epoch: {epoch} computing scores\")\n",
    "\n",
    "    pos_scores = compute_edge_scores(embeddings)[data.edge_index[0], data.edge_index[1]]\n",
    "    neg_scores = compute_edge_scores(embeddings)[negative_edge_index[0], negative_edge_index[1]]\n",
    "    \n",
    "    # Labels: 1s for positive samples, 0s for negative samples\n",
    "    labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])])\n",
    "    scores = torch.cat([pos_scores, neg_scores])\n",
    "    \n",
    "    print(f\"epoch: {epoch} concluding\")\n",
    "    loss = criterion(scores, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8133, Precision: 0.5000, Recall: 1.0000, F1: 0.6667\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(predictions, labels):\n",
    "    # Binarize predictions based on a threshold\n",
    "    threshold = 0.5\n",
    "    preds = predictions > threshold\n",
    "    labels = labels.bool()\n",
    "    \n",
    "    # True positives, false positives, true negatives, false negatives\n",
    "    tp = (preds & labels).sum().float()\n",
    "    fp = (preds & ~labels).sum().float()\n",
    "    tn = (~preds & ~labels).sum().float()\n",
    "    fn = (~preds & labels).sum().float()\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data)\n",
    "        pos_edge_index = data.edge_index\n",
    "        neg_edge_index = negative_sampling(edge_index=pos_edge_index, num_nodes=data.num_nodes, num_neg_samples=pos_edge_index.size(1))\n",
    "\n",
    "        pos_scores = compute_edge_scores(embeddings)[pos_edge_index[0], pos_edge_index[1]]\n",
    "        neg_scores = compute_edge_scores(embeddings)[neg_edge_index[0], neg_edge_index[1]]\n",
    "        scores = torch.cat([pos_scores, neg_scores], dim=0)\n",
    "        labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])], dim=0)\n",
    "\n",
    "        val_loss = criterion(scores, labels)\n",
    "        precision, recall, f1 = calculate_metrics(scores, labels)\n",
    "        \n",
    "        print(f'Validation Loss: {val_loss.item():.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65be7af-685c-453a-b5bc-cc3f4af648a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14280ed4-63a0-4316-b9de-7833884871cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d6d328-4504-4aac-9741-75c4b39050b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (11, 0)\t1.0\n",
      "  (14, 0)\t1.0\n",
      "  (15, 0)\t1.0\n",
      "  (18, 0)\t1.0\n",
      "  (19, 0)\t1.0\n",
      "  (20, 0)\t1.0\n",
      "  (21, 0)\t1.0\n",
      "  (22, 0)\t1.0\n",
      "  (23, 0)\t1.0\n",
      "  (24, 0)\t1.0\n",
      "  (25, 0)\t1.0\n",
      "  (28, 0)\t1.0\n",
      "  (30, 0)\t1.0\n",
      "  (31, 0)\t1.0\n",
      "  (32, 0)\t1.0\n",
      "  (33, 0)\t1.0\n",
      "  :\t:\n",
      "  (12806, 1)\t1.0\n",
      "  (12808, 1)\t1.0\n",
      "  (12809, 1)\t1.0\n",
      "  (12810, 1)\t1.0\n",
      "  (12811, 1)\t1.0\n",
      "  (12812, 1)\t1.0\n",
      "  (12815, 1)\t1.0\n",
      "  (12817, 1)\t1.0\n",
      "  (12818, 1)\t1.0\n",
      "  (12820, 1)\t1.0\n",
      "  (12821, 1)\t1.0\n",
      "  (12823, 1)\t1.0\n",
      "  (12827, 1)\t1.0\n",
      "  (12829, 1)\t1.0\n",
      "  (12830, 1)\t1.0\n",
      "  (12831, 1)\t1.0\n",
      "  (12832, 1)\t1.0\n",
      "  (12833, 1)\t1.0\n",
      "  (12834, 1)\t1.0\n",
      "  (12835, 1)\t1.0\n",
      "  (12837, 1)\t1.0\n",
      "  (12838, 1)\t1.0\n",
      "  (12839, 1)\t1.0\n",
      "  (12840, 1)\t1.0\n",
      "  (12841, 1)\t1.0\n",
      "<class 'scipy.sparse._csc.csc_matrix'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mat = loadmat('..\\\\results\\\\var_k\\dblp\\\\res_dblp_exp_4_002_128.mat')\n",
    "features_matrix = mat['embs']\n",
    "\n",
    "mat = loadmat(\"../data/dblp.mat\")\n",
    "A = mat[\"network\"]\n",
    "labels_matrix = mat[\"group\"]\n",
    "labels_count = labels_matrix.shape[1]\n",
    "\n",
    "print(labels_matrix)\n",
    "\n",
    "print(type(labels_matrix))\n",
    "\n",
    "groups = labels_matrix.toarray()\n",
    "\n",
    "print(type(groups[:5, :5]))\n",
    "print(groups[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7aa3b4-c3dc-4a59-8e1f-a4eb32f65c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TopKRanker(OneVsRestClassifier):\n",
    "    def predict(self, gram_test, top_k_list):\n",
    "        assert gram_test.shape[0] == len(top_k_list)\n",
    "        probs = np.asarray(super(TopKRanker, self).predict_proba(gram_test))\n",
    "        all_labels = []\n",
    "        for i, k in enumerate(top_k_list):\n",
    "            probs_ = probs[i, :]\n",
    "            labels = self.classes_[probs_.argsort()[-k:]].tolist()\n",
    "            all_labels.append(labels)\n",
    "        return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78dac11-ad47-4758-8582-a7512c80f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [1. 0.]]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "3998\n",
      "9328\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Example data creation\n",
    "n = 13326  # Number of items\n",
    "num_groups = 2  # Number of groups\n",
    "#groups = np.random.randint(0, 2, size=(n, num_groups))  # Random binary groups matrix\n",
    "print(groups[:5])\n",
    "#groups = sparse.random(n, num_groups, density=0.2, format='csr', data_rvs=np.ones).toarray()  # Sparse binary groups matrix with 20% density\n",
    "\n",
    "# Creating DataFrame for features\n",
    "df_features = pd.DataFrame(features_matrix, columns=[f'feature_{i}' for i in range(128)])\n",
    "#print(df_features.head())\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, groups, test_size=0.3, random_state=42)\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "print(len(y_test))\n",
    "print(len(y_train))\n",
    "print(y_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b541eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.49\n",
      "Average Recall: 1.00\n",
      "Average F1 Score: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2246\n",
      "           1       0.99      0.95      0.97      1807\n",
      "\n",
      "   micro avg       0.98      0.97      0.97      4053\n",
      "   macro avg       0.98      0.96      0.97      4053\n",
      "weighted avg       0.98      0.97      0.97      4053\n",
      " samples avg       0.98      0.97      0.97      4053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = TopKRanker(SVC(kernel=\"precomputed\",cache_size=4096,probability=True))\n",
    "gram = squareform( 1 - pdist(X_train, 'hamming'));\n",
    "gram_test = 1 - cdist(X_test, X_train, 'hamming');\n",
    "\n",
    "clf.fit(gram, y_train)\n",
    "\n",
    "top_k_list = [len(l) for l in y_test]\n",
    "preds = clf.predict(gram_test, top_k_list)\n",
    "mlb = MultiLabelBinarizer(classes=range(2))\n",
    "f1_score(mlb.fit_transform(y_test), mlb.fit_transform(preds), average='micro')\n",
    "\n",
    "accuracy = accuracy_score(mlb.fit_transform(y_test), mlb.fit_transform(preds), normalize=False) / y_test.size\n",
    "recalls = recall_score(mlb.fit_transform(y_test), mlb.fit_transform(preds), average=None)  # Returns recall for each class\n",
    "f1s = f1_score(mlb.fit_transform(y_test), mlb.fit_transform(preds), average=None)  # Returns F1 score for each class\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Average Recall: {np.mean(recalls):.2f}\")\n",
    "print(f\"Average F1 Score: {np.mean(f1s):.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf9277b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (11, 0)\t1.0\n",
      "  (14, 0)\t1.0\n",
      "  (15, 0)\t1.0\n",
      "  (18, 0)\t1.0\n",
      "  (19, 0)\t1.0\n",
      "  (20, 0)\t1.0\n",
      "  (21, 0)\t1.0\n",
      "  (22, 0)\t1.0\n",
      "  (23, 0)\t1.0\n",
      "  (24, 0)\t1.0\n",
      "  (25, 0)\t1.0\n",
      "  (28, 0)\t1.0\n",
      "  (30, 0)\t1.0\n",
      "  (31, 0)\t1.0\n",
      "  (32, 0)\t1.0\n",
      "  (33, 0)\t1.0\n",
      "  :\t:\n",
      "  (12806, 1)\t1.0\n",
      "  (12808, 1)\t1.0\n",
      "  (12809, 1)\t1.0\n",
      "  (12810, 1)\t1.0\n",
      "  (12811, 1)\t1.0\n",
      "  (12812, 1)\t1.0\n",
      "  (12815, 1)\t1.0\n",
      "  (12817, 1)\t1.0\n",
      "  (12818, 1)\t1.0\n",
      "  (12820, 1)\t1.0\n",
      "  (12821, 1)\t1.0\n",
      "  (12823, 1)\t1.0\n",
      "  (12827, 1)\t1.0\n",
      "  (12829, 1)\t1.0\n",
      "  (12830, 1)\t1.0\n",
      "  (12831, 1)\t1.0\n",
      "  (12832, 1)\t1.0\n",
      "  (12833, 1)\t1.0\n",
      "  (12834, 1)\t1.0\n",
      "  (12835, 1)\t1.0\n",
      "  (12837, 1)\t1.0\n",
      "  (12838, 1)\t1.0\n",
      "  (12839, 1)\t1.0\n",
      "  (12840, 1)\t1.0\n",
      "  (12841, 1)\t1.0\n",
      "<class 'scipy.sparse._csc.csc_matrix'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "mat = loadmat('..\\\\results\\\\var_k\\dblp\\\\res_dblp_exp_2_002_128.mat')\n",
    "features_matrix = mat['embs']\n",
    "\n",
    "mat = loadmat(\"../data/dblp.mat\")\n",
    "A = mat[\"network\"]\n",
    "labels_matrix = mat[\"group\"]\n",
    "labels_count = labels_matrix.shape[1]\n",
    "\n",
    "print(labels_matrix)\n",
    "\n",
    "print(type(labels_matrix))\n",
    "\n",
    "groups = labels_matrix.toarray()\n",
    "\n",
    "print(type(groups[:5, :5]))\n",
    "print(groups[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27320e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [1. 0.]]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "3998\n",
      "9328\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Example data creation\n",
    "n = 13326  # Number of items\n",
    "num_groups = 2  # Number of groups\n",
    "#groups = np.random.randint(0, 2, size=(n, num_groups))  # Random binary groups matrix\n",
    "print(groups[:5])\n",
    "#groups = sparse.random(n, num_groups, density=0.2, format='csr', data_rvs=np.ones).toarray()  # Sparse binary groups matrix with 20% density\n",
    "\n",
    "# Creating DataFrame for features\n",
    "df_features = pd.DataFrame(features_matrix, columns=[f'feature_{i}' for i in range(128)])\n",
    "#print(df_features.head())\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, groups, test_size=0.3, random_state=42)\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "print(len(y_test))\n",
    "print(len(y_train))\n",
    "print(y_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f93043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.49\n",
      "Average Recall: 1.00\n",
      "Average F1 Score: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2246\n",
      "           1       0.98      0.96      0.97      1807\n",
      "\n",
      "   micro avg       0.98      0.97      0.97      4053\n",
      "   macro avg       0.98      0.97      0.97      4053\n",
      "weighted avg       0.98      0.97      0.97      4053\n",
      " samples avg       0.98      0.97      0.98      4053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = TopKRanker(SVC(kernel=\"precomputed\",cache_size=4096,probability=True))\n",
    "gram = squareform( 1 - pdist(X_train, 'hamming'));\n",
    "gram_test = 1 - cdist(X_test, X_train, 'hamming');\n",
    "\n",
    "clf.fit(gram, y_train)\n",
    "\n",
    "top_k_list = [len(l) for l in y_test]\n",
    "preds = clf.predict(gram_test, top_k_list)\n",
    "mlb = MultiLabelBinarizer(classes=range(2))\n",
    "f1_score(mlb.fit_transform(y_test), mlb.fit_transform(preds), average='micro')\n",
    "\n",
    "accuracy = accuracy_score(mlb.fit_transform(y_test), mlb.fit_transform(preds), normalize=False) / y_test.size\n",
    "recalls = recall_score(mlb.fit_transform(y_test), mlb.fit_transform(preds), average=None)  # Returns recall for each class\n",
    "f1s = f1_score(mlb.fit_transform(y_test), mlb.fit_transform(preds), average=None)  # Returns F1 score for each class\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Average Recall: {np.mean(recalls):.2f}\")\n",
    "print(f\"Average F1 Score: {np.mean(f1s):.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf7b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
